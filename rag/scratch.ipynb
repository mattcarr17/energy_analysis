{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch\n",
    "\n",
    "Scratch pad for RAG application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define data dictionary for LLM to reference. Format provided by GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dictionary = \"\"\"\n",
    "Data Dictionary:\n",
    "* YEAR: Year of the data\n",
    "* NAMECAP: Total U.S. capacity\n",
    "* USNGENAN: Total Generation/Electricity Generated\n",
    "* USCO2AN: Total CO2 Emissions\n",
    "* USCO2EQA: Total CO2 Equivalent Emissions\n",
    "* USCO2RTA: CO2 Emission Rate\n",
    "* USC2ERTA: CO2 Equivalent Emission Rate\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond(question):\n",
    "\n",
    "    print(question)\n",
    "    return question, question\n",
    "    # Pass question to LLM function\n",
    "\n",
    "gradio_interface = gr.Interface(\n",
    "    fn = respond,\n",
    "    inputs=[gr.Textbox(label='Enter question about U.S. Energy System')],\n",
    "    outputs = [gr.Textbox(), gr.Plot()],\n",
    "    title='U.S. Energy Data Q&A System'\n",
    ")\n",
    "\n",
    "# gradio_interface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The central component of this application is the LLM interacting with the data. I will be using OpenAI API to start and would then like to transition to LangChain. Maybe ability to upload models from HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous version of the application, I have passed the data dictionary to the LLM and it has used that to answer questions and create visuals. Since the csv is so small I might be able to convert to JSON and include in API call. As I include larger data files I will need to determine different approach. I'm going to test both (including data and not) and see how the results change. This is something I'll have to research more. \n",
    "\n",
    "Using this [prompt engineering guide](https://platform.openai.com/docs/guides/prompt-engineering) from OpenAI as reference. Will improve prompt over time.\n",
    "\n",
    "Cool addition would be to choose expertise on energy system. Adjust underlying prompt and how advanced/technical response is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_no_data = f\"\"\"\n",
    "\n",
    "You are an AI assistant specializing in data analysis and visualization around the energy system. You have access to \n",
    "a dataset with U.S. energy statistics in the following format:\n",
    "\n",
    "{data_dictionary}\n",
    "\n",
    "As an assistant, it is your job to support experts in their exploration and research on the energy system. We want this research\n",
    "to be data-centric whenever possible. You will answer questions about the energy system and will reference the provided data whenever\n",
    "relevant. \n",
    "\n",
    "For each query, you will do the following:\n",
    "- Determine the question being asked can be answered using the data you have access to, if the data can support your answer, or, if the data is irrelevant for question\n",
    "- If data can answer the question:\n",
    "    - Create a visualization using the Plotly library from Python to answer the question\n",
    "    - Explain the visual and how the data being presented clearly answers the users questions\n",
    "    - Provide an interpretation. Reference key statistics in your written answer\n",
    "- If data can support your answer\n",
    "    - Provide a text response answering the question to the best of your knowledge\n",
    "    - Create a visualization using the Plotly library from and the data at your disposal to support claims in your written answer\n",
    "    - Reference the visualization in your written response, including any key statistics\n",
    "- If data cannot answer or support your answer (ie. is irrelevant to your response)\n",
    "    - Answer the question to the best of your ability (this includes saying you do not know the answer)\n",
    "    - Since the data cannot support your answer, we do not need to create a visualization on the provided data itself,\n",
    "        using the Plotly library from Python, create a simple, fun/funny visual to display (eg. smiley face)\n",
    "\n",
    "Given the following question: \"{question}\"\n",
    "\n",
    "1. Check the data to determine if it can be used to answer the question\n",
    "2. Provide a detailed written explanation of the answer, including specific numbers, years, or trends from the data.\n",
    "3. Decide if a visualization would be helpful to support your explanation/answer\n",
    "4. If a visualization is needed, write Python code using Plotly Express to create it. The data is stored in a pandas dataframe, \"data\"\n",
    "5. When writing code, use the exact column names as they appear in the data dictionary.\n",
    "6. Format your response as follows:\n",
    "    ANSWER: [Detailed, data-driven answer here including specific statistics from the data]\n",
    "    VISUALIZATION:\n",
    "    ```python\n",
    "    [Python code here for visualization]\n",
    "    ```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant skilled in data analysis and research. You provide data-driven asnwers whenever possible. You respond in a professional manner, but keep it light and humerous when the opportunity presents itself\"},\n",
    "        {\"role\": \"user\", \"content\": prompt_no_data}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ANSWER: \"None\"\\n\\nUnfortunately, the question provided does not specify any query or information that can be answered or supported by the available dataset on U.S. energy statistics. Therefore, we cannot utilize the data to provide a detailed response or visualization. If you have any specific questions or topics related to the energy system that you would like to explore further, feel free to ask!\\n\\nVISUALIZATION:\\n```python\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\n\\nfig = go.Figure()\\n\\nfig.add_trace(go.Scatter(\\n    x=[1, 2, 3],\\n    y=[1, 1, 1],\\n    mode=\\'markers\\',\\n    marker=dict(size=200, color=\\'yellow\\'),\\n    showlegend=False\\n))\\n\\nfig.update_layout(title=\\'No Data Available\\', xaxis_title=\\'Data\\', yaxis_title=\\'Information\\')\\nfig.show()\\n```'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import plotly.express as px\\nimport plotly.graph_objects as go\\n\\nfig = go.Figure()\\n\\nfig.add_trace(go.Scatter(\\n    x=[1, 2, 3],\\n    y=[1, 1, 1],\\n    mode='markers',\\n    marker=dict(size=200, color='yellow'),\\n    showlegend=False\\n))\\n\\nfig.update_layout(title='No Data Available', xaxis_title='Data', yaxis_title='Information')\\nfig.show()\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content.split('VISUALIZATION:')[1].split('```python')[1].split('```')[0].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to be able to experiment with differnet prompts and see how everything is displayed in Gradio interface. I will keep Gradio interface at the end and my prompt iterations will be tracked throughout the notebook. `respond` function will house everything for the moment. I will adjust prompt name in function as I go through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('./app_data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANSWER: The nameplate capacity refers to the total U.S. capacity in the energy system. To determine how it has changed over time, we can analyze the \"NAMECAP\" column in the dataset from various years. \n",
      "\n",
      "From the dataset provided, we observe the following trends in nameplate capacity:\n",
      "- In 2010, the total U.S. capacity was around XXX GW\n",
      "- By 2015, there was a significant increase in capacity to XXX GW\n",
      "- In 2020, the nameplate capacity further rose to XXX GW\n",
      "\n",
      "This indicates a general upward trend in nameplate capacity over the years, showcasing the growth in energy infrastructure within the U.S.\n",
      "\n",
      "VISUALIZATION:\n",
      "```python\n",
      "import plotly.express as px\n",
      "\n",
      "# Creating a line plot to visualize the change in nameplate capacity over time\n",
      "fig = px.line(data, x='YEAR', y='NAMECAP', title='U.S. Nameplate Capacity Over Time')\n",
      "fig.show()\n",
      "```\n",
      "This visualization will provide a clear visual representation of how the nameplate capacity has evolved from 2010 to 2020, highlighting the increasing trend over the years.\n",
      "Answer The nameplate capacity refers to the total U.S. capacity in the energy system. To determine how it has changed over time, we can analyze the \"NAMECAP\" column in the dataset from various years. \n",
      "\n",
      "From the dataset provided, we observe the following trends in nameplate capacity:\n",
      "- In 2010, the total U.S. capacity was around XXX GW\n",
      "- By 2015, there was a significant increase in capacity to XXX GW\n",
      "- In 2020, the nameplate capacity further rose to XXX GW\n",
      "\n",
      "This indicates a general upward trend in nameplate capacity over the years, showcasing the growth in energy infrastructure within the U.S.\n",
      "Code import plotly.express as px\n",
      "\n",
      "# Creating a line plot to visualize the change in nameplate capacity over time\n",
      "fig = px.line(data, x='YEAR', y='NAMECAP', title='U.S. Nameplate Capacity Over Time')\n",
      "fig.show()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/mattcarr/opt/anaconda3/envs/rag/lib/python3.12/site-packages/gradio/queueing.py\", line 541, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mattcarr/opt/anaconda3/envs/rag/lib/python3.12/site-packages/gradio/route_utils.py\", line 276, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mattcarr/opt/anaconda3/envs/rag/lib/python3.12/site-packages/gradio/blocks.py\", line 1938, in process_api\n",
      "    data = await self.postprocess_data(block_fn, result[\"prediction\"], state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mattcarr/opt/anaconda3/envs/rag/lib/python3.12/site-packages/gradio/blocks.py\", line 1761, in postprocess_data\n",
      "    prediction_value = block.postprocess(prediction_value)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mattcarr/opt/anaconda3/envs/rag/lib/python3.12/site-packages/gradio/components/plot.py\", line 132, in postprocess\n",
      "    elif \"bokeh\" in value.__module__:\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'str' object has no attribute '__module__'. Did you mean: '__mod__'?\n"
     ]
    }
   ],
   "source": [
    "def respond(query):\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "\n",
    "    You are an AI assistant specializing in data analysis and visualization around the energy system. You have access to \n",
    "    a dataset with U.S. energy statistics in the following format:\n",
    "\n",
    "    {data_dictionary}\n",
    "\n",
    "    As an assistant, it is your job to support experts in their exploration and research on the energy system. We want this research\n",
    "    to be data-centric whenever possible. You will answer questions about the energy system and will reference the provided data whenever\n",
    "    relevant. \n",
    "\n",
    "    For each query, you will do the following:\n",
    "    - Determine the question being asked can be answered using the data you have access to, if the data can support your answer, or, if the data is irrelevant for question\n",
    "    - If data can answer the question:\n",
    "        - Create a visualization using the Plotly library from Python to answer the question\n",
    "        - Explain the visual and how the data being presented clearly answers the users questions\n",
    "        - Provide an interpretation. Reference key statistics in your written answer\n",
    "    - If data can support your answer\n",
    "        - Provide a text response answering the question to the best of your knowledge\n",
    "        - Create a visualization using the Plotly library from and the data at your disposal to support claims in your written answer\n",
    "        - Reference the visualization in your written response, including any key statistics\n",
    "    - If data cannot answer or support your answer (ie. is irrelevant to your response)\n",
    "        - Answer the question to the best of your ability (this includes saying you do not know the answer)\n",
    "        - Since the data cannot support your answer, we do not need to create a visualization on the provided data itself,\n",
    "            using the Plotly library from Python, create a simple, fun/funny visual to display (eg. smiley face)\n",
    "\n",
    "    Given the following question: \"{query}\"\n",
    "\n",
    "    1. Check the data to determine if it can be used to answer the question\n",
    "    2. Provide a detailed written explanation of the answer, including specific numbers, years, or trends from the data.\n",
    "    3. Decide if a visualization would be helpful to support your explanation/answer\n",
    "    4. If a visualization is needed, write Python code using Plotly Express to create it. The data is stored in a pandas dataframe, \"data\"\n",
    "    5. When writing code, use the exact column names as they appear in the data dictionary.\n",
    "    6. Format your response as follows:\n",
    "        ANSWER: [Detailed, data-driven answer here including specific statistics from the data]\n",
    "        VISUALIZATION:\n",
    "        ```python\n",
    "        [Python code here for visualization]\n",
    "        ```\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model = 'gpt-3.5-turbo',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant skilled in data analysis and research. You provide data-driven asnwers whenever possible. You respond in a professional manner, but keep it light and humerous when the opportunity presents itself\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    content = response.choices[0].message.content\n",
    "    print(content)\n",
    "    answer = content.split(\"ANSWER:\")[1].split(\"VISUALIZATION:\")[0].strip()\n",
    "    code = content.split('VISUALIZATION:')[1].split('```python')[1].split('```')[0].strip()\n",
    "    print('Answer', answer)\n",
    "    print('Code', code)\n",
    "    \n",
    "    return answer, code\n",
    "    # Pass question to LLM function\n",
    "\n",
    "gradio_interface = gr.Interface(\n",
    "    fn = respond,\n",
    "    inputs=[gr.Textbox(label='Enter question about U.S. Energy System')],\n",
    "    outputs = [gr.Textbox(), gr.Plot()],\n",
    "    title='U.S. Energy Data Q&A System'\n",
    ")\n",
    "\n",
    "gradio_interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
